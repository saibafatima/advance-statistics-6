{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d37c6be-2662-4555-92bf-d4119af1f69d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1451215338.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\n",
    "To use ANOVA, certain assumptions must be met:\n",
    "\n",
    "The data should be normally distributed.\n",
    "The samples should be independent and randomly selected.\n",
    "The variances of the groups should be equal (homogeneity of variance).\n",
    "Violations of these assumptions can impact the validity of the results. For example, if the data is not normally distributed, the p-values may not be accurate. If the samples are not independent, the results may be biased. If the variances are not equal, the F-test may not be reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb7fab2-ab10-4756-a8f5-b810eaab6057",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (497473105.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    There are three types of ANOVA:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "There are three types of ANOVA:\n",
    "\n",
    "One-way ANOVA\n",
    "Used when there is one independent variable, one-way ANOVA allows for the evaluation of the effect of the independent variable on the dependent variable. For example, it could be used to understand the impact of employee training on customer satisfaction ratings.\n",
    "\n",
    "Two-way ANOVA\n",
    "Used when there are two independent variables, two-way ANOVA allows for the evaluation of the individual and joint effects of the variables. For example, it could be used to understand the impact of both advertising spend and product placement on sales revenue.\n",
    "\n",
    "Factorial ANOVA\n",
    "Used when there are more than two independent variables, factorial ANOVA allows for the evaluation of the combined effects of the variables. For example, a business might use a factorial ANOVA to examine the combined effects of age, income, and education level on consumer purchasing habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5129fcd5-d557-46f7-a693-3845e67722a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1033697064.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    In ANOVA, the total variance is partitioned into three components: the variance explained by the independent variable (SSE), the variance not explained by the independent variable (SSR), and the total variance (SST). Understanding this concept is important because it allows us to quantify the amount of variance explained by the independent variable and determine whether the results are statistically significant.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "In ANOVA, the total variance is partitioned into three components: the variance explained by the independent variable (SSE), the variance not explained by the independent variable (SSR), and the total variance (SST). Understanding this concept is important because it allows us to quantify the amount of variance explained by the independent variable and determine whether the results are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502f42e7-f2d9-4152-8503-9548ffa51c87",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (777312412.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    y is the response variable (a 1D array or list)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "\n",
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can use the following steps:\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "y is the response variable (a 1D array or list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ca415d0-59b7-4254-9f5a-bc61472fe9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 82.5\n",
      "SSE: 41.83333333333332\n",
      "SSR: 40.66666666666668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def anova_sums(y, groups):\n",
    "    # Calculate the overall mean\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    # Calculate the total sum of squares (SST)\n",
    "    sst = np.sum((y - y_mean) ** 2)\n",
    "\n",
    "    # Calculate the explained sum of squares (SSE)\n",
    "    groups_unique, groups_counts = np.unique(groups, return_counts=True)\n",
    "    sse = 0\n",
    "    for group in groups_unique:\n",
    "        group_mean = np.mean(y[groups == group])\n",
    "        sse += groups_counts[np.where(groups_unique == group)[0][0]] * (group_mean - y_mean) ** 2\n",
    "\n",
    "    # Calculate the residual sum of squares (SSR)\n",
    "    ssr = sst - sse\n",
    "\n",
    "    return sst, sse, ssr\n",
    "\n",
    "# Example usage\n",
    "y = np.array([23, 21, 19, 24, 20, 18, 22, 25, 26, 27])\n",
    "groups = np.array(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'])\n",
    "\n",
    "sst, sse, ssr = anova_sums(y, groups)\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9916fe5-7a36-4438-8ec3-f84d231c36c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (525442043.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    y is the response variable (a 1D array or list)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "\n",
    "To calculate the main effects and interaction effects in a two-way ANOVA using Python, you can use the following steps:\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "y is the response variable (a 1D array or list)\n",
    "factor1 and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13747ca-0b78-4ea7-90e1-92893c46e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSA (Factor 1): 105.66666666666664\n",
      "SSB (Factor 2): 1.5\n",
      "SSAB (Interaction): 17.361111111111118\n",
      "SSR (Residual): 15.0\n",
      "SST (Total): 139.52777777777777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def two_way_anova(y, factor1, factor2):\n",
    "    # Calculate the overall mean\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    # Calculate the main effect of factor1\n",
    "    factor1_unique, factor1_counts = np.unique(factor1, return_counts=True)\n",
    "    factor1_means = np.array([np.mean(y[factor1 == level]) for level in factor1_unique])\n",
    "    ssa = np.sum(factor1_counts * (factor1_means - y_mean) ** 2)\n",
    "\n",
    "    # Calculate the main effect of factor2\n",
    "    factor2_unique, factor2_counts = np.unique(factor2, return_counts=True)\n",
    "    factor2_means = np.array([np.mean(y[factor2 == level]) for level in factor2_unique])\n",
    "    ssb = np.sum(factor2_counts * (factor2_means - y_mean) ** 2)\n",
    "\n",
    "    # Calculate the interaction effect\n",
    "    interaction_means = np.array([[np.mean(y[(factor1 == level1) & (factor2 == level2)]) \n",
    "                                   for level2 in factor2_unique] \n",
    "                                  for level1 in factor1_unique])\n",
    "    ssab = np.sum((interaction_means - factor1_means[:, np.newaxis] - factor2_means[np.newaxis, :] + y_mean) ** 2)\n",
    "\n",
    "    # Calculate the residual sum of squares (SSR)\n",
    "    ssr = 0\n",
    "    for i in range(len(y)):\n",
    "        idx1 = np.where(factor1_unique == factor1[i])[0][0]\n",
    "        idx2 = np.where(factor2_unique == factor2[i])[0][0]\n",
    "        ssr += (y[i] - interaction_means[idx1, idx2]) ** 2\n",
    "\n",
    "    # Calculate the total sum of squares (SST)\n",
    "    sst = ssa + ssb + ssab + ssr\n",
    "\n",
    "    return ssa, ssb, ssab, ssr, sst\n",
    "\n",
    "# Example usage\n",
    "y = np.array([23, 21, 19, 24, 20, 18, 22, 25, 26, 27, 28, 29])\n",
    "factor1 = np.array(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D'])\n",
    "factor2 = np.array(['X', 'X', 'Y', 'X', 'X', 'Y', 'X', 'X', 'Y', 'X', 'X', 'Y'])\n",
    "\n",
    "ssa, ssb, ssab, ssr, sst = two_way_anova(y, factor1, factor2)\n",
    "print(\"SSA (Factor 1):\", ssa)\n",
    "print(\"SSB (Factor 2):\", ssb)\n",
    "print(\"SSAB (Interaction):\", ssab)\n",
    "print(\"SSR (Residual):\", ssr)\n",
    "print(\"SST (Total):\", sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f911e51c-4fb2-461d-aef2-3b29dd124a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c16b0204-0efa-4748-9b0d-a170cd215df2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1948119494.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    Conclusion and Interpretation:\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "\n",
    "\n",
    "Conclusion and Interpretation:\n",
    "\n",
    "Based on the results of the one-way ANOVA, we can conclude that there are significant differences between the groups.\n",
    "\n",
    "F-statistic (5.23): The F-statistic measures the ratio of the variance between groups to the variance within groups. A large F-statistic indicates that the variance between groups is significantly larger than the variance within groups, suggesting that the groups are significantly different.\n",
    "\n",
    "p-value (0.02): The p-value represents the probability of observing the F-statistic (or a more extreme value) assuming that there are no real differences between the groups (i.e., the null hypothesis is true). A p-value of 0.02 indicates that there is only a 2% chance of observing the F-statistic (or a more extreme value) if there are no real differences between the groups.\n",
    "\n",
    "Since the p-value is less than the typical significance level of 0.05, we reject the null hypothesis and conclude that there are statistically significant differences between the groups.\n",
    "\n",
    "Interpretation: The results suggest that at least one of the groups is significantly different from the others. This means that the factor or variable being studied has a significant effect on the response variable. However, the ANOVA results do not indicate which specific groups are different from each other or how they differ.\n",
    "\n",
    "To further explore the differences between the groups, you may want to consider:\n",
    "\n",
    "Post-hoc tests: Conduct pairwise comparisons between groups to determine which specific groups are significantly different from each other.\n",
    "Mean comparisons: Examine the group means to understand the direction and magnitude of the differences between groups.\n",
    "Effect size analysis: Calculate effect sizes (e.g., eta-squared) to quantify the size of the differences between groups.\n",
    "By interpreting the results of the one-way ANOVA, you can gain insights into the relationships between the factor and the response variable, and make informed decisions about the significance of the differences between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff35b5d8-ed44-4ee3-8cca-85695fb8b34c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (351684053.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Handling Missing Data in Repeated Measures ANOVA:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data? \n",
    "Handling Missing Data in Repeated Measures ANOVA:\n",
    "\n",
    "In a repeated measures ANOVA, missing data can be handled using various methods, each with its own strengths and limitations. Here are some common methods:\n",
    "\n",
    "Listwise Deletion: Drop all rows with missing values. This method is simple but can lead to biased results if the missingness is not random.\n",
    "Pairwise Deletion: Drop only the specific data points that are missing. This method can lead to inconsistent results if the missingness is not random.\n",
    "Mean Imputation: Replace missing values with the mean of the respective variable. This method can lead to underestimation of variance and covariance.\n",
    "Regression Imputation: Replace missing values using a regression model. This method can lead to overestimation of significance if the imputation model is not accurate.\n",
    "Multiple Imputation: Replace missing values using multiple imputation techniques, such as Bayesian imputation or bootstrapping. This method can provide a more accurate estimate of the uncertainty associated with the missing data.\n",
    "Maximum Likelihood Estimation: Use maximum likelihood estimation to estimate the model parameters, taking into account the missing data. This method is more complex but can provide unbiased results.\n",
    "Potential Consequences of Using Different Methods:\n",
    "\n",
    "The choice of method to handle missing data can have significant consequences on the results and interpretation of the repeated measures ANOVA. Here are some potential consequences:\n",
    "\n",
    "Bias: Using listwise deletion or mean imputation can lead to biased results if the missingness is not random.\n",
    "Inconsistent Results: Pairwise deletion can lead to inconsistent results if the missingness is not random and the analysis is sensitive to the specific data points.\n",
    "Underestimation of Variance: Mean imputation can lead to underestimation of the variance and covariance, which can affect the significance of the results.\n",
    "Overestimation of Significance: Regression imputation or multiple imputation can lead to overestimation of the significance of the results if the imputation model is not accurate.\n",
    "Increased Type I Error Rate: Using a method that does not account for the uncertainty associated with the missing data can lead to an increased type I error rate.\n",
    "Loss of Power: Using listwise deletion or pairwise deletion can lead to a loss of power, especially if the missingness is not random.\n",
    "Best Practice:\n",
    "\n",
    "The best practice is to use a combination of methods, such as multiple imputation and maximum likelihood estimation, to handle missing data in repeated measures ANOVA. It is also essential to carefully evaluate the missing data mechanism and choose a method that is appropriate for the specific research question and data characteristics.\n",
    "\n",
    "Python Implementation:\n",
    "\n",
    "Here is an example of how to handle missing data using multiple imputation in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c68b1c9-55ed-48e9-bf0c-6e3716178771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "=================================\n",
      "     F Value Num DF Den DF Pr > F\n",
      "---------------------------------\n",
      "Time  5.1481 2.0000 4.0000 0.0783\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = {'Subject': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'Time': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "        'Value': [10, 12, np.nan, 8, 10, 12, 9, 11, 13]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Impute missing values using multiple imputation\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "imputed_data = imputer.fit_transform(df[['Value']].values.reshape(-1, 1))\n",
    "df['Value'] = pd.Series(imputed_data.flatten())\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "anova_rm = AnovaRM(df, 'Value', 'Subject', within=['Time'])\n",
    "print(anova_rm.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea3aae08-9746-44e3-9667-d7f78aac404e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plant_growth_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_tukeyhsd\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplant_growth_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Perform ANOVA\u001b[39;00m\n\u001b[1;32m     11\u001b[0m anova_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrowth ~ fertilizer\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plant_growth_data.csv'"
     ]
    }
   ],
   "source": [
    "#Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('plant_growth_data.csv')\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_model = sm.ols('growth ~ fertilizer', data=df).fit()\n",
    "anova_results = anova_model.anova_lr_test()\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "posthoc_results = pairwise_tukeyhsd(endog=df['growth'], groups=df['fertilizer'], alpha=0.05)\n",
    "\n",
    "print(posthoc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8209cd5f-2945-4d96-8ddc-f41a753a9852",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/file/plant_growth_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/your/file/plant_growth_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/file/plant_growth_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/path/to/your/file/plant_growth_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0b5480f-3a3c-4116-a924-af825278a726",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/your/file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplant_growth_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/file'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/path/to/your/file')\n",
    "df = pd.read_csv('plant_growth_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ebd1c48-e197-45d7-95fd-65db80da6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sum_sq     df        F    PR(>F)\n",
      "C(Diet)      5.32    2.0  0.09443  0.909946\n",
      "Residual  4140.84  147.0      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load the data\n",
    "data = {\n",
    "    'Diet': np.repeat(['A', 'B', 'C'], 50),\n",
    "    'Weight_Loss': np.random.randint(5, 25, 150)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "model = ols('Weight_Loss ~ C(Diet)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dc81eef-7d74-4822-8089-dc98b51aadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df          F    PR(>F)\n",
      "C(Software)                460.548656   2.0  14.103153  0.000012\n",
      "C(Experience)                0.319352   1.0   0.019559  0.889297\n",
      "C(Software):C(Experience)   61.202333   2.0   1.874169  0.163330\n",
      "Residual                   881.704530  54.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "#Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# Load the data\n",
    "np.random.seed(0)\n",
    "software_means = [20, 25, 30]\n",
    "experience_means = [2, 5]\n",
    "software_stds = [2, 3, 2]\n",
    "experience_stds = [1, 2]\n",
    "\n",
    "data = {\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 20),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 30),\n",
    "    'Time': np.concatenate([\n",
    "        np.random.normal(loc=software_means[i] + experience_means[j], scale=software_stds[i] + experience_stds[j], size=10)\n",
    "        for i in range(3) for j in range(2)\n",
    "    ])\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1b61222-0765-461a-8921-b859d06c637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -1.5267455833477102\n",
      "p-value: 0.13004538960951503\n",
      "The results are not significant. There is no significant difference in test scores between the two groups.\n"
     ]
    }
   ],
   "source": [
    "#Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=50)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"The results are significant. There is a significant difference in test scores between the two groups.\")\n",
    "else:\n",
    "    print(\"The results are not significant. There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# Follow up with a post-hoc test (in this case, a simple comparison of means)\n",
    "if p_val < 0.05:\n",
    "    print(\"\\nPost-hoc test results:\")\n",
    "    print(\"Control group mean:\", np.mean(control_scores))\n",
    "    print(\"Experimental group mean:\", np.mean(experimental_scores))\n",
    "    if np.mean(control_scores) < np.mean(experimental_scores):\n",
    "        print(\"The experimental group has significantly higher test scores than the control group.\")\n",
    "    else:\n",
    "        print(\"The control group has significantly higher test scores than the experimental group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4d56644-b370-48f2-a1f5-600baf2defdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated measures ANOVA results:\n",
      "                sum_sq    df         F    PR(>F)\n",
      "C(Store)  5.101753e+04   2.0  0.525074  0.593374\n",
      "Residual  4.226570e+06  87.0       NaN       NaN\n",
      "The results are not significant. There is no significant difference in sales between the three stores.\n"
     ]
    }
   ],
   "source": [
    "#Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "#significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other.\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "store_a_sales = np.random.normal(loc=1000, scale=200, size=30)\n",
    "store_b_sales = np.random.normal(loc=1200, scale=250, size=30)\n",
    "store_c_sales = np.random.normal(loc=1100, scale=220, size=30)\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "data = {\n",
    "    'Day': range(1, 31),\n",
    "    'Store A': store_a_sales,\n",
    "    'Store B': store_b_sales,\n",
    "    'Store C': store_c_sales\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame for repeated measures ANOVA\n",
    "melted_df = pd.melt(df, id_vars='Day', var_name='Store', value_name='Sales')\n",
    "\n",
    "# Conduct repeated measures ANOVA\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols('Sales ~ C(Store)', data=melted_df).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "print(\"Repeated measures ANOVA results:\")\n",
    "print(anova_table)\n",
    "\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    print(\"The results are significant. There is a significant difference in sales between the three stores.\")\n",
    "else:\n",
    "    print(\"The results are not significant. There is no significant difference in sales between the three stores.\")\n",
    "\n",
    "# Follow up with a post-hoc test (Tukey's HSD)\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    print(\"\\nPost-hoc test results:\")\n",
    "    tukey_results = pairwise_tukeyhsd(endog=melted_df['Sales'], groups=melted_df['Store'], alpha=0.05)\n",
    "    print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acc671-7782-497b-ab2a-04e000aae72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
